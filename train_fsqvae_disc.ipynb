{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codec\n",
    "\n",
    "We're going to see if FSQ is a good fit for finding the tokens we need for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import equinox as eqx\n",
    "import equinox.nn as nn\n",
    "import jax.numpy as jnp\n",
    "\n",
    "class Encoder(eqx.Module):\n",
    "    conv0: nn.Conv1d\n",
    "    conv1: nn.Conv1d\n",
    "    conv2: nn.Conv1d\n",
    "    conv3: nn.Conv1d\n",
    "    conv4: nn.Conv1d\n",
    "    conv7: nn.Conv1d\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, latent_channels, kernel_size=5, key=None):\n",
    "        key0, key1, key2, key3, key4, key7 = jax.random.split(key, 6)\n",
    "        self.conv0 = nn.Conv1d(\n",
    "            in_channels,\n",
    "            hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=\"SAME\",\n",
    "            use_bias=False,\n",
    "            key=key0,            \n",
    "        )\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            hidden_channels * 1,\n",
    "            hidden_channels * 4,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=2,\n",
    "            padding=\"SAME\",\n",
    "            key=key1,\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            hidden_channels * 4,\n",
    "            hidden_channels * 8,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=2,\n",
    "            padding=\"SAME\",\n",
    "            key=key2,\n",
    "        )\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            hidden_channels * 8,\n",
    "            hidden_channels * 16,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=5,\n",
    "            padding=\"SAME\",\n",
    "            key=key3,\n",
    "        )\n",
    "        self.conv4= nn.Conv1d(\n",
    "            hidden_channels * 16,\n",
    "            hidden_channels * 16,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=5,\n",
    "            padding=\"SAME\",\n",
    "            key=key4,\n",
    "        )\n",
    "        self.conv7 = nn.Conv1d(\n",
    "            hidden_channels * 16, latent_channels, kernel_size=1, key=key7\n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, x):\n",
    "        y = self.conv0(x)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv1(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv2(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv3(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv4(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv7(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class Decoder(eqx.Module):\n",
    "    conv0: nn.ConvTranspose1d\n",
    "    conv1: nn.ConvTranspose1d\n",
    "    conv2: nn.ConvTranspose1d\n",
    "    conv5: nn.ConvTranspose1d\n",
    "    conv6: nn.ConvTranspose1d\n",
    "    conv7: nn.ConvTranspose1d\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, latent_channels, kernel_size=5, key=None):\n",
    "        key0, key1, key2, key3, key4, key5, key6, key7 = jax.random.split(key, 8)\n",
    "        self.conv0 = nn.ConvTranspose1d(\n",
    "            latent_channels,\n",
    "            hidden_channels * 16,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=\"SAME\",\n",
    "            key=key0,            \n",
    "        )\n",
    "        self.conv1 = nn.ConvTranspose1d(\n",
    "            hidden_channels * 16,\n",
    "            hidden_channels * 16,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=5,\n",
    "            padding=\"SAME\",\n",
    "            key=key1,\n",
    "        )\n",
    "        self.conv2 = nn.ConvTranspose1d(\n",
    "            hidden_channels * 16,\n",
    "            hidden_channels * 8,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=5,\n",
    "            padding=\"SAME\",\n",
    "            key=key2,\n",
    "        )\n",
    "        self.conv5= nn.ConvTranspose1d(\n",
    "            hidden_channels * 8,\n",
    "            hidden_channels * 4,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=2,\n",
    "            padding=\"SAME\",\n",
    "            key=key5,\n",
    "        )\n",
    "        self.conv6= nn.ConvTranspose1d(\n",
    "            hidden_channels * 4,\n",
    "            hidden_channels * 1,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=2,\n",
    "            padding=\"SAME\",\n",
    "            key=key6,\n",
    "        )\n",
    "        self.conv7 = nn.ConvTranspose1d(\n",
    "            hidden_channels, in_channels, kernel_size=kernel_size, stride=1, use_bias=False, padding=\"SAME\", key=key7\n",
    "        )\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, x):\n",
    "        y = self.conv0(x)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv1(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv2(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv5(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv6(y)\n",
    "        y = jax.nn.relu(y)\n",
    "        y = self.conv7(y)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jax.random.normal(key=jax.random.key(1), shape=(1, 16000))\n",
    "enc = Encoder(1, 4, 1, 5, key=jax.random.key(1))\n",
    "dec = Decoder(1, 4, 1, 5, key=jax.random.key(1))\n",
    "\n",
    "y = enc(x)\n",
    "z = dec(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the code from the google repo for the FSQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Codeword = jax.Array\n",
    "Indices = jax.Array\n",
    "\n",
    "\n",
    "class FSQ(eqx.Module):\n",
    "    \"\"\"Quantizer, taken from https://github.com/google-research/google-research/blob/master/fsq/fsq.ipynb\"\"\"\n",
    "\n",
    "    _levels: list[int]\n",
    "    _levels_np: jax.Array\n",
    "    _eps: float\n",
    "    _basis: jax.Array\n",
    "    _implicit_codebook: jax.Array\n",
    "\n",
    "    def __init__(self, levels: list[int], eps: float = 1e-3):\n",
    "        self._levels = levels\n",
    "        self._eps = eps\n",
    "        self._levels_np = jnp.asarray(levels)\n",
    "        self._basis = jnp.concatenate(\n",
    "            (jnp.array([1]), jnp.cumprod(self._levels_np[:-1]))\n",
    "        )\n",
    "\n",
    "        self._implicit_codebook = self.indexes_to_codes(jnp.arange(self.codebook_size))\n",
    "\n",
    "    @property\n",
    "    def num_dimensions(self) -> int:\n",
    "        \"\"\"Number of dimensions expected from inputs.\"\"\"\n",
    "        return len(self._levels)\n",
    "\n",
    "    @property\n",
    "    def codebook_size(self):\n",
    "        \"\"\"Size of the codebook.\"\"\"\n",
    "        return jnp.prod(jnp.array(self._levels))\n",
    "\n",
    "    @property\n",
    "    def codebook(self):\n",
    "        \"\"\"Returns the implicit codebook. Shape (prod(levels), num_dimensions).\"\"\"\n",
    "        return self._implicit_codebook\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def round_ste(self, z):\n",
    "        \"\"\"Round with straight through gradients.\"\"\"\n",
    "        zhat = jnp.round(z)\n",
    "        return z + jax.lax.stop_gradient(zhat - z)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def bound(self, z: jax.Array) -> jax.Array:\n",
    "        \"\"\"Bound `z`, an array of shape (..., d).\"\"\"\n",
    "        half_l = (self._levels_np - 1) * (1 - self._eps) / 2\n",
    "        offset = jnp.where(self._levels_np % 2 == 1, 0.0, 0.5)\n",
    "        shift = jnp.tan(offset / half_l)\n",
    "        return jnp.tanh(z + shift) * half_l - offset\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, z: jax.Array) -> Codeword:\n",
    "        \"\"\"Quanitzes z, returns quantized zhat, same shape as z.\"\"\"\n",
    "        quantized = self.round_ste(self.bound(z))\n",
    "\n",
    "        # Renormalize to [-1, 1].\n",
    "        half_width = self._levels_np // 2\n",
    "        return quantized / half_width\n",
    "\n",
    "    def _scale_and_shift(self, zhat_normalized):\n",
    "        # Scale and shift to range [0, ..., L-1]\n",
    "        half_width = self._levels_np // 2\n",
    "        return (zhat_normalized * half_width) + half_width\n",
    "\n",
    "    def _scale_and_shift_inverse(self, zhat):\n",
    "        half_width = self._levels_np // 2\n",
    "        return (zhat - half_width) / half_width\n",
    "\n",
    "    def codes_to_indexes(self, zhat: Codeword) -> Indices:\n",
    "        \"\"\"Converts a `code` to an index in the codebook.\"\"\"\n",
    "        assert zhat.shape[-1] == self.num_dimensions\n",
    "        zhat = self._scale_and_shift(zhat)\n",
    "        return (zhat * self._basis).sum(axis=-1).astype(jnp.uint32)\n",
    "\n",
    "    def indexes_to_codes(self, indices: Indices) -> Codeword:\n",
    "        \"\"\"Inverse of `indexes_to_codes`.\"\"\"\n",
    "        indices = indices[..., jnp.newaxis]\n",
    "        codes_non_centered = jnp.mod(\n",
    "            jnp.floor_divide(indices, self._basis), self._levels_np\n",
    "        )\n",
    "        return self._scale_and_shift_inverse(codes_non_centered)\n",
    "\n",
    "\n",
    "class VQVAE(eqx.Module):\n",
    "    encoder: Encoder\n",
    "    decoder: Decoder\n",
    "    quantizer: FSQ\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, latent_channels, levels, key=None):\n",
    "        key1, key2 = jax.random.split(key)\n",
    "\n",
    "        self.encoder = Encoder(in_channels, hidden_channels, latent_channels, key=key1)\n",
    "        self.decoder = Decoder(in_channels, hidden_channels, latent_channels, key=key2)\n",
    "        self.quantizer = FSQ(levels=levels)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, x):\n",
    "        # x = jnp.expand_dims(x, 0)\n",
    "        \n",
    "        z_e = self.encoder(x)\n",
    "        reshaped_z_e = jnp.reshape(z_e, (-1, 5)) #16000 Hz -> 16Hz = 1000 points per code downsampled from 1000 to 5. Map each set of 5 to their respective code and map back. There are 4 levels thus 5 * (2 ** 4) = 80bits per codeword\n",
    "        reshaped_z_q = self.quantizer(reshaped_z_e)\n",
    "        z_q = jnp.reshape(reshaped_z_q, z_e.shape)\n",
    "        y = self.decoder(z_q)\n",
    "        # print(z_e)\n",
    "        # print(z_e.shape)\n",
    "        # print(reshaped_z_e.shape)\n",
    "        # print(self.quantizer.codes_to_indexes(jnp.expand_dims(reshaped_z_q, -1)))\n",
    "        # y = jnp.squeeze(y|)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jax.random.normal(key=jax.random.key(0), shape=(16000))\n",
    "model = VQVAE(1, 4, 1, [4], key=jax.random.key(4))\n",
    "y = model(x)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "# print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it and see what results we get !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model initialized\n",
      "✅ Models initialized\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optax\n",
    "from tensorboardX import SummaryWriter\n",
    "from datasets import load_dataset\n",
    "import datetime\n",
    "from layers.hifigan import MultiScaleDiscriminator, MultiPeriodDiscriminator\n",
    "import jax\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import librosa\n",
    "key1, key2 = jax.random.split(jax.random.key(2), 2)\n",
    "\n",
    "model = VQVAE(1, 32, 4, [8], key=key1)\n",
    "optimizer = optax.adam(1e-5)\n",
    "opt_state = optimizer.init(model)\n",
    "\n",
    "scale_disc = MultiScaleDiscriminator(key=jax.random.key(1))\n",
    "scale_optimizer = optax.adam(1e-4)\n",
    "scale_opt_state = optimizer.init(scale_disc)\n",
    "\n",
    "period_disc = MultiPeriodDiscriminator(key=jax.random.key(1))\n",
    "period_optimizer = optax.adam(1e-4)\n",
    "period_opt_state = optimizer.init(period_disc)\n",
    "\n",
    "print(\"✅ Models initialized\")\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 4\n",
    "step = 0\n",
    "\n",
    "dataset = load_dataset(\"blabble-io/libritts_r\", \"clean\", streaming=True)\n",
    "\n",
    "def cut_up(samples):\n",
    "    list = []\n",
    "    for sample in samples[\"audio\"]:\n",
    "        resampled = librosa.resample(sample[\"array\"], orig_sr=22050, target_sr=16000)\n",
    "        for i in range(0, (int(len(resampled)//16000) -1)):\n",
    "            list.append(resampled[i*16000:i*16000+16000])\n",
    "    return {\"audio\": list}\n",
    "\n",
    "dataset = dataset.map(cut_up, batched=True, remove_columns=['text_normalized', 'text_original', 'speaker_id', 'path', 'chapter_id', 'id'])\n",
    "\n",
    "dataloader= dataset[\"train.clean.360\"].batch(batch_size=batch_size)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "@eqx.filter_value_and_grad(has_aux=True)\n",
    "def calculate_losses(model, disc, period, x):\n",
    "    y = jax.vmap(model)(x)\n",
    "    # y = jnp.expand_dims(y, 1)\n",
    "    fake_pred, _ = jax.vmap(disc)(y) # At what point does disc think it's a true\n",
    "    G_loss = 0\n",
    "    for fake in fake_pred:\n",
    "        G_loss += jax.numpy.mean((fake - 1) ** 2)\n",
    "    return G_loss, y\n",
    "\n",
    "@eqx.filter_jit\n",
    "@eqx.filter_value_and_grad\n",
    "def calc_disc_loss(disc, x, y):\n",
    "    fake_pred, _ = jax.vmap(disc)(y)\n",
    "    real_pred, _ = jax.vmap(disc)(x)\n",
    "    loss = 0\n",
    "    for fake_res, real_res in zip(fake_pred, real_pred):\n",
    "        fake_loss = jax.numpy.mean((fake_res) ** 2)\n",
    "        real_loss = jax.numpy.mean((real_res - 1) ** 2)\n",
    "        loss += fake_loss + real_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, scale, period, optimizer, opt_state, scale_optimizer, scale_opt_state, period_optimizer, period_opt_state, x):\n",
    "    (total_loss, y), grads = calculate_losses(model, scale, period, x)        \n",
    "    updates, opt_state = optimizer.update(grads, opt_state, model)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    \n",
    "    scale_loss, grads = calc_disc_loss(scale, x, y)\n",
    "    updates, scale_opt_state = scale_optimizer.update(grads, scale_opt_state, scale)\n",
    "    scale = eqx.apply_updates(scale, updates)\n",
    "    \n",
    "    period_loss, grads = calc_disc_loss(period, x, y)\n",
    "    updates, period_opt_state = period_optimizer.update(grads, period_opt_state, period)\n",
    "    period = eqx.apply_updates(period, updates)\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        scale,\n",
    "        period,\n",
    "        opt_state,\n",
    "        scale_opt_state,\n",
    "        period_opt_state,\n",
    "        total_loss,\n",
    "        scale_loss,\n",
    "        period_loss,\n",
    "        y\n",
    "    )\n",
    "fig, ax = plt.subplots(1)\n",
    "fig.show()\n",
    "step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mexpand_dims(jnp\u001b[38;5;241m.\u001b[39marray(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     model, scale_disc, period_disc, opt_state, scale_opt_state, period_opt_state, total_loss, scale_loss, period_loss, y \u001b[38;5;241m=\u001b[39m \u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_disc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod_disc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_opt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod_opt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Log codebook updates to TensorBoard\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/equinox/_module.py:953\u001b[0m, in \u001b[0;36m_unflatten_module\u001b[0;34m(cls, aux, dynamic_field_values)\u001b[0m\n\u001b[1;32m    943\u001b[0m     aux \u001b[38;5;241m=\u001b[39m _FlattenedData(\n\u001b[1;32m    944\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(dynamic_field_names),\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(static_field_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(wrapper_field_values),\n\u001b[1;32m    949\u001b[0m     )\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(dynamic_field_values), aux\n\u001b[0;32m--> 953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unflatten_module\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m], aux: _FlattenedData, dynamic_field_values):\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;66;03m# This doesn't go via `__init__`. A user may have done something nontrivial there,\u001b[39;00m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;66;03m# and the field values may be dummy values as used in various places throughout JAX.\u001b[39;00m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;66;03m# See also\u001b[39;00m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;66;03m# https://jax.readthedocs.io/en/latest/pytrees.html#custom-pytrees-and-initialization,\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;66;03m# which was (I believe) inspired by Equinox's approach here.\u001b[39;00m\n\u001b[1;32m    959\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(aux\u001b[38;5;241m.\u001b[39mdynamic_field_names, dynamic_field_values):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # eqx.tree_serialise_leaves(f\"checkpoints/{epoch}.eqx\", model)\n",
    "    for batch in dataloader:\n",
    "        input = jnp.expand_dims(jnp.array(batch[\"audio\"]), 1)\n",
    "        model, scale_disc, period_disc, opt_state, scale_opt_state, period_opt_state, total_loss, scale_loss, period_loss, y = make_step(model, scale_disc, period_disc, optimizer, opt_state, scale_optimizer, scale_opt_state, period_optimizer, period_opt_state, input)\n",
    "\n",
    "        # Log codebook updates to TensorBoard\n",
    "        step+=1\n",
    "        writer.add_scalar('Loss/FSQ', total_loss, step)\n",
    "        writer.add_scalar('Loss/ScaleDiscriminator', scale_loss, step)\n",
    "        writer.add_scalar('Loss/PeriodDiscriminator', period_loss, step)\n",
    "        if (step // batch_size) % 20 == 0:\n",
    "            ax.clear()\n",
    "            ax.plot(input[0][0])\n",
    "            ax.plot(y[0][0])\n",
    "            display(fig)\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# print(*model.quantizer._levels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model initialized\n",
      "(16000,)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "x = jax.random.normal(key=jax.random.key(0), shape=(16000))\n",
    "model = VQVAE(1, 4, 1, [4], key=jax.random.key(4))\n",
    "y = model(x)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "# print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = model(sample)\n",
    "z = model.encoder(jnp.expand_dims(sample, 0))\n",
    "codes = model.quantizer.codes_to_indexes(jnp.expand_dims(model.quantizer(z), -1))\n",
    "print(codes)\n",
    "\n",
    "IPython.display.Audio(y, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "fig.show()\n",
    "ax.plot(sample)\n",
    "ax.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqx.tree_serialise_leaves(\"checkpoints/fsq.eqx\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
