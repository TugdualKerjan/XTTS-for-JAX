{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Cannot set attribute initial",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, clear_output\n\u001b[1;32m     14\u001b[0m key1, key2 \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mkey(\u001b[38;5;241m2\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mVQVAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39madam(\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     19\u001b[0m opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39minit(model)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/XTTS-for-JAX/layers/VQVAE.py:289\u001b[0m, in \u001b[0;36mVQVAE.__init__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    286\u001b[0m key1, key2, key3 \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m Encoder(key\u001b[38;5;241m=\u001b[39mkey1)\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m \u001b[43mDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantizer \u001b[38;5;241m=\u001b[39m Quantizer(decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, key\u001b[38;5;241m=\u001b[39mkey3)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/XTTS-for-JAX/layers/VQVAE.py:155\u001b[0m, in \u001b[0;36mDecoder.__init__\u001b[0;34m(self, hidden_dim, codebook_dim, key)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m, codebook_dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    153\u001b[0m     key1, key2, key3, key4, key5, key6, key7 \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key, \u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial\u001b[49m \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv1d(\n\u001b[1;32m    156\u001b[0m         in_channels\u001b[38;5;241m=\u001b[39mcodebook_dim,\n\u001b[1;32m    157\u001b[0m         out_channels\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[1;32m    158\u001b[0m         kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    159\u001b[0m         stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    160\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAME\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    161\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey1,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres1 \u001b[38;5;241m=\u001b[39m ResBlock(dim\u001b[38;5;241m=\u001b[39mhidden_dim, key\u001b[38;5;241m=\u001b[39mkey2)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m UpsampledConv(\n\u001b[1;32m    165\u001b[0m         in_channels\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[1;32m    166\u001b[0m         out_channels\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey5,\n\u001b[1;32m    171\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/equinox/_module.py:854\u001b[0m, in \u001b[0;36m_make_initable.<locals>.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Cannot set attribute initial"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "from tensorboardX import SummaryWriter\n",
    "from layers.VQVAE import VQVAE\n",
    "from datasets import load_dataset\n",
    "import datetime\n",
    "\n",
    "import jax\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "key1, key2 = jax.random.split(jax.random.key(2), 2)\n",
    "\n",
    "model = VQVAE(key=key1)\n",
    "\n",
    "optimizer = optax.adam(1e-4)\n",
    "opt_state = optimizer.init(model)\n",
    "\n",
    "writer = SummaryWriter(log_dir='./runs/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "step = 0\n",
    "\n",
    "dataset = load_dataset(\"blabble-io/libritts_r\", \"clean\", streaming=True)\n",
    "\n",
    "freq = 15\n",
    "stride = int(22050 / freq)\n",
    "def cut_up(samples):\n",
    "    # print(int(len(sample[\"audio\"][\"array\"])//stride))\n",
    "    list = []\n",
    "    for sample in samples[\"audio\"]:\n",
    "        for i in range(0, (int(len(sample[\"array\"])//stride) -1)):\n",
    "            list.append(sample[\"array\"][i*stride:i*stride+stride])\n",
    "    return {\"audio\": list}\n",
    "\n",
    "dataset = dataset.map(cut_up, batched=True, remove_columns=['text_normalized', 'text_original', 'speaker_id', 'path', 'chapter_id', 'id'])\n",
    "\n",
    "dataloader= dataset[\"train.clean.360\"].batch(batch_size=batch_size)\n",
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m key1, grab \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key1)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39marray(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 79\u001b[0m model, opt_state, total_loss, reconstruct_loss, commit_loss, codebook_updates, y \u001b[38;5;241m=\u001b[39m \u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Log codebook updates to TensorBoard\u001b[39;00m\n\u001b[1;32m     82\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss/Total\u001b[39m\u001b[38;5;124m'\u001b[39m, total_loss, step)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtts/lib/python3.10/site-packages/equinox/_module.py:953\u001b[0m, in \u001b[0;36m_unflatten_module\u001b[0;34m(cls, aux, dynamic_field_values)\u001b[0m\n\u001b[1;32m    943\u001b[0m     aux \u001b[38;5;241m=\u001b[39m _FlattenedData(\n\u001b[1;32m    944\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(dynamic_field_names),\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(static_field_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(wrapper_field_values),\n\u001b[1;32m    949\u001b[0m     )\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(dynamic_field_values), aux\n\u001b[0;32m--> 953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unflatten_module\u001b[39m(\u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m], aux: _FlattenedData, dynamic_field_values):\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;66;03m# This doesn't go via `__init__`. A user may have done something nontrivial there,\u001b[39;00m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;66;03m# and the field values may be dummy values as used in various places throughout JAX.\u001b[39;00m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;66;03m# See also\u001b[39;00m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;66;03m# https://jax.readthedocs.io/en/latest/pytrees.html#custom-pytrees-and-initialization,\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;66;03m# which was (I believe) inspired by Equinox's approach here.\u001b[39;00m\n\u001b[1;32m    959\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(aux\u001b[38;5;241m.\u001b[39mdynamic_field_names, dynamic_field_values):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def update_codebook_ema(model, updates: tuple, codebook_indices, key=None):\n",
    "    avg_updates = jax.tree.map(lambda x: jax.numpy.mean(x, axis=0), updates)\n",
    "\n",
    "    # Calculate which codes are too often used and yeet them. Prior is uniform.\n",
    "    h = jnp.histogram(\n",
    "        codebook_indices, bins=model.quantizer.K, range=(0, model.quantizer.K)\n",
    "    )[0] / len(codebook_indices)\n",
    "    part_that_should_be = 1 / model.quantizer.K\n",
    "    mask = (h > 2 * part_that_should_be) | (h < 0.5 * part_that_should_be)\n",
    "    rand_embed = (\n",
    "        jax.random.normal(key, (model.quantizer.K, model.quantizer.D)) * mask[:, None]\n",
    "    )\n",
    "    avg_updates = (\n",
    "        jnp.where(mask[:], 0, avg_updates[0]),\n",
    "        jnp.where(mask[:, None], rand_embed, avg_updates[1]),\n",
    "        jnp.where(mask[:, None], rand_embed, avg_updates[2]),\n",
    "    )\n",
    "\n",
    "    where = lambda q: (\n",
    "        q.quantizer.cluster_size,\n",
    "        q.quantizer.codebook_avg,\n",
    "        q.quantizer.codebook,\n",
    "    )\n",
    "\n",
    "    # Update the codebook and other trackers.\n",
    "    model = eqx.tree_at(where, model, avg_updates)\n",
    "    return model\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "@eqx.filter_value_and_grad(has_aux=True)\n",
    "def calculate_losses(model, x):\n",
    "    z_e, z_q, codebook_updates, y = jax.vmap(model)(x)\n",
    "    y = y[:, :-2]\n",
    "    # Are the inputs and outputs close?\n",
    "    reconstruct_loss = jnp.mean(jnp.linalg.norm((x - y), ord=2, axis=(0, 1)))\n",
    "\n",
    "    # Are the output vectors z_e close to the codes z_q ?\n",
    "    commit_loss = jnp.mean(\n",
    "        jnp.linalg.norm(z_e - jax.lax.stop_gradient(z_q), ord=2, axis=(0, 1))\n",
    "    )\n",
    "    # codebook = jnp.mean(codebook_updates[0][2], axis=0) #| hide_line\n",
    "    # print(codebook.shape) #| hide_line\n",
    "    # print(codebook) #| hide_line\n",
    "    # print(jnp.mean(codebook, axis=-1).shape) #| hide_line\n",
    "    # print(f\"STDR: {jnp.std(codebook, axis=-1)}\") #| hide_line\n",
    "    # print(f\"log: {jnp.log(jnp.clip(jnp.mean(codebook, axis=-1), min=1e-5)) }\") #| hide_line\n",
    "    # KL_loss = 0.5 * jnp.sum(jnp.mean(codebook, axis=-1)**2 + jnp.var(codebook, axis=-1)  #| hide_line- jnp.log(jnp.clip(jnp.std(codebook, axis=-1), min=1e-6)) - 1) #| hide_line\n",
    "\n",
    "    total_loss = reconstruct_loss + commit_loss\n",
    "\n",
    "    return total_loss, (reconstruct_loss, commit_loss, codebook_updates, y)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, optimizer, opt_state, x, key):\n",
    "    (total_loss, (reconstruct_loss, commit_loss, codebook_updates, y)), grads = (\n",
    "        calculate_losses(model, x)\n",
    "    )\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, model)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    model = update_codebook_ema(model, codebook_updates[0], codebook_updates[1], key)\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        opt_state,\n",
    "        total_loss,\n",
    "        reconstruct_loss,\n",
    "        commit_loss,\n",
    "        codebook_updates,\n",
    "        y,\n",
    "    )\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # eqx.tree_serialise_leaves(f\"checkpoints/{epoch}.eqx\", model)\n",
    "    for batch in dataloader:\n",
    "        key1, grab = jax.random.split(key1)\n",
    "        input = jax.numpy.array(batch[\"audio\"])\n",
    "        model, opt_state, total_loss, reconstruct_loss, commit_loss, codebook_updates, y = make_step(model, optimizer, opt_state, input, grab)\n",
    "\n",
    "        # Log codebook updates to TensorBoard\n",
    "        writer.add_scalar('Loss/Total', total_loss, step)\n",
    "        writer.add_scalar('Loss/Reconstruct', reconstruct_loss, step)\n",
    "        writer.add_scalar('Loss/Commit', commit_loss, step)\n",
    "        step += 1\n",
    "        writer.add_histogram('Codebook Updates/Code ids used', jnp.reshape(codebook_updates[1], -1), step)\n",
    "        writer.add_histogram('Codebook Updates/Code means', jnp.mean(codebook_updates[0][2], axis=(0,2)), step)\n",
    "        writer.add_histogram('Codebook Updates/Code stds', jnp.std(codebook_updates[0][2], axis=(0,2)), step)\n",
    "        # if (step // batch_size) % 20 == 0:\n",
    "        #     ax1.clear()\n",
    "        #     ax2.clear()\n",
    "        #     ax1.plot(batch[\"audio\"][0])\n",
    "        #     ax2.plot(y[0])\n",
    "        #     display(fig)\n",
    "        #     clear_output(wait=True)\n",
    "    # plt.imshow(y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.quantizer.codebook.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example = next(iter(dataloader2))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "fig.show()\n",
    "print(example)\n",
    "ax1.plot(example[\"audio\"][0][\"array\"][3528:3528+3528])\n",
    "\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.VQVAE import VQVAE\n",
    "\n",
    "import jax\n",
    "\n",
    "model = VQVAE(key=jax.random.key(1))\n",
    "\n",
    "x = jax.numpy.ones(1000)\n",
    "\n",
    "y = model.encoder(x)\n",
    "\n",
    "print(y.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
